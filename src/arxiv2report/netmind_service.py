import requests
import json
from config import settings
from typing import List, Dict, Tuple, Any
import re

class NetmindService:
    def __init__(self):
        self.api_key = settings.netmind_api_key
        self.url = "https://api.netmind.ai/inference-api/agent/v1/parse-pdf"

    def get_response_from_pdf(self, pdf_url: str) -> List[Dict[str, Any]]|None:
        # Response:
        # json_response	array
        # An array of objects representing the response data.
        # 	id	string
        # 	The random id for the item.
        # 	version	string
        # 	Version for maintain.
        # 	page	integer
        # 	The page number.
        # 	seq_no	integer
        # 	The block No. in each page.
        # 	type	string
        # 	The block type.
        # 	sentence	string
        # 	The sentence or text content of the item.
        # 	refined_sentence	string
        # 	The refined sentence or text content of the item.
        # 	image	array
        # 	An array of objects representing the image data. type==image is required.
        # 		path	string
        # 		The URL of the image.
        # 		desc	string
        # 		The description of the image.
        # 	text_location	object
        # 	The location information of the text in a structured format.
        # 		location	array
        # 		Cartesian Coordinate System for location.
        # 		location_raw	array
        # 		Screen Coordinate System for location.
        # 	info	object
        # 	Additional information about the item, currently empty.
        # markdown_resp	string
        # Return the markdown text in Text format.
        
        payload = json.dumps({
            "url": pdf_url,
            "format": "json",
            "vlm": False
        })
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }

        response = requests.request("POST", self.url, headers=headers, data=payload, proxies={"http": "", "https": ""})
        response.raise_for_status()  # Raise an exception for bad status codes
        try:
            full_response: List[Dict[str, Any]] = json.loads(response.text)
            return full_response
        except Exception as e:
            print(f"Failed to get or parse Netmind response: {e}")
    
    def get_images_from_pdf(self, pdf_url: str) -> Dict[str, Tuple[str, str]]:
            # 1. 获取并解析完整的 API 响应
            # 2. 提取 json_response
            # json_response 是一个列表，包含了 PDF 中所有内容块（文本、表格、图片等）
            json_response= self.get_response_from_pdf(pdf_url)
            if json_response is None:
                return {}
            
            image_url_ids = []
            image_urls = []
            captions = []
            keys = []

            for i, item in enumerate(json_response):
                if item['type'] == 'image':
                    image_url_ids.append(i)
                    image_urls.append(item['image_detail'][0]['path'])

            for i in image_url_ids:
                sentence = json_response[i+1]['sentence']
                # 截取从 'Fig. or Figure' 开始到句子结束的字符串
                caption = re.search(r'(Fig\.|Figure).*', sentence).group()
                # 提取 caption 中的图编号数字
                figure_number = re.search(r'\d+', caption).group()
                keys.append(f"figure_{figure_number}")
                captions.append(caption)

            figure_dict = dict(zip(keys, zip(image_urls, captions)))
            return figure_dict


if __name__ == '__main__':
    # Manual test for NetmindService
    pdf_url = "https://arxiv.org/pdf/2506.04980"
    netmind_service = NetmindService()
    image_urls = netmind_service.get_images_from_pdf(pdf_url)
    print(image_urls)
    exit()

    json_text = r"""
[{"id":"l4orEt5G","version":"1.0.1","page":1,"seq_no":1,"sentence":"Agentic AI for Intent-Based Industrial Automation","type":"title","text_location":{"location":[[49,790,547,766]],"location_raw":[[49,51,547,75]]},"info":{}},{"id":"H8FyFBvE","version":"1.0.1","page":1,"seq_no":2,"sentence":"Marcos Lima Romero Center for Engineering, Modeling and Applied Social Sciences Federal University of ABC - UFABC Santo Andr´e, Brazil https://orcid.org/0009-0008-1406-6349 Ricardo Suyama Center for Engineering, Modeling and Applied Social Sciences Federal University of ABC - UFABC Santo Andre´, Brazil https://orcid.org/0000-0002-8398-5268","type":"sentence","text_location":{"location":[[107,749,267,675]],"location_raw":[[107,92,267,166]]},"info":{}},{"id":"NnWHxw7H","version":"1.0.1","page":1,"seq_no":3,"sentence":"Abstract—The recent development of Agentic AI systems, empowered by autonomous large language models (LLMs) agents with planning and tool-usage capabilities, enables new possibilities for the evolution of industrial automation and reduces the complexity introduced by Industry 4.0. This work proposes a conceptual framework that integrates Agentic AI with the intent-based paradigm, originally developed in net- work research, to simplify human–machine interaction (HMI) and better align automation systems with the human-centric, sustainable, and resilient principles of Industry 5.0. Based on the intent-based processing, the framework allows human operators to express high-level business or operational goals in natural language, which are decomposed into actionable components. These intents are broken into expectations, con- ditions, targets, context, and information that guide sub-agents equipped with specialized tools to execute domain-specific tasks. A proof of concept was implemented using the CMAPSS dataset and Google Agent Developer Kit (ADK), demonstrating the feasibility of intent decomposition, agent orchestration, and autonomous decision-making in predictive maintenance scenarios. The results confirm the potential of this approach to reduce technical barriers and enable scalable, intent-driven automation, despite data quality and explainability concerns.","type":"sentence","text_location":{"location":[[46,636,291,406]],"location_raw":[[46,205,291,435]]},"info":{}},{"id":"1fNOgmFs","version":"1.0.1","page":1,"seq_no":4,"sentence":"Index Terms—agentic ai, intent-based, industry 5.0, manu- facturing, automation","type":"sentence","text_location":{"location":[[45,405,291,386]],"location_raw":[[45,436,291,455]]},"info":{}},{"id":"0YDYmkwc","version":"1.0.1","page":1,"seq_no":5,"sentence":"I. INTRODUCTION","type":"title","text_location":{"location":[[129,372,208,362]],"location_raw":[[129,469,208,479]]},"info":{}},{"id":"6nKMXK3z","version":"1.0.1","page":1,"seq_no":6,"sentence":"Since the advent of Industry 4.0 in the mid-2010s, the volume of data generated by industrial enterprises has grown exponentially. A recent study by ABI Research projects that annual data production in the industrial sector will increase from 1.9 zettabytes (ZB) to  4.4~\\mathrm{ZB}  by 2030 [1]. Cyber-physical systems have bridged the physical and dig- ital worlds, enabling machines, products, and management systems to communicate and exchange data in real time through Industrial Internet of Things (IIoT) networks. As a result, production processes have become highly automated, optimized through Big Data analytics and AI, and capable of dynamically adapting to changes. Mass customization and on-demand production have become increasingly feasible, while data-driven predictive maintenance strategies help pre- vent unexpected downtime [2].","type":"sentence","text_location":{"location":[[46,356,292,177]],"location_raw":[[46,485,292,664]]},"info":{}},{"id":"UvB1wIoM","version":"1.0.1","page":1,"seq_no":7,"sentence":"However, although these technological advances have sig- nificantly improved industrial capabilities, they have also in- troduced new layers of complexity for human operators, who must now manage massive volumes of data and oversee the operation of increasingly sophisticated systems [3]. Industry 5.0 introduces a shift toward a human-centric approach to address this emerging gap.","type":"sentence","text_location":{"location":[[46,176,291,129]],"location_raw":[[46,665,291,712]]},"info":{}},{"id":"ZkcrEjxY","version":"1.0.1","page":1,"seq_no":8,"sentence":"Based on the ongoing adoption of the principles of Indus- try 4.0, Industry 5.0, as defined by the European Commis- sion, proposes new essential pillars for the next industrial era: human-centric approach, sustainability, and resilience [4]. It emphasizes the adoption of human-centered strategies, wherein technology is not designed to replace human labor but to augment and sustainably enhance human capabilities. This vision is closely aligned with the United Nations Sustainable Development Goals (SDGs), particularly Goals 8, 9, and 12 — Decent Work and Economic Growth; Industry, Innovation, and Infrastructure; and Responsible Consumption and Production [5].","type":"sentence","text_location":{"location":[[303,599,549,457]],"location_raw":[[303,242,549,384]]},"info":{}},{"id":"2E7QeuqU","version":"1.0.1","page":1,"seq_no":9,"sentence":"In this context, AI emerges as a key enabler of Industry 5.0, helping to bridge the gap between the increasing com- plexity of systems and the need for more intuitive human in- teractions. Through natural language communication, Large Language Models (LLMs) have gained widespread adoption, allowing users to perform complex tasks with just a few rounds of prompt-based conversation [6]. Building on this advancement, LLM-based agents are now being developed with enhanced capabilities, including reasoning, planning, and the ability to use specialized tools to autonomously execute specific tasks [7]. These tasks can range from sim- ple system status inquiries to the orchestration of complex business or operational intent requests.","type":"sentence","text_location":{"location":[[303,455,549,300]],"location_raw":[[303,386,549,541]]},"info":{}},{"id":"FndpWwhT","version":"1.0.1","page":1,"seq_no":10,"sentence":"In line with the human-centric vision of Industry 5.0, communication based on intentions becomes a fundamen- tal paradigm. Rather than requiring users to provide step- by-step instructions focusing on how to do, intent-based communication enables them to express what they want to achieve clearly and naturally. The system interprets these high-level intents and autonomously determines the optimal actions to fulfill them [8]. This paradigm shift aims to make interactions with complex technological environments more intuitive, efficient, and resilient, reducing operational errors and supporting continuous adaptation to evolving goals and operational scenarios.","type":"sentence","text_location":{"location":[[303,299,549,157]],"location_raw":[[303,542,549,684]]},"info":{}},{"id":"FNWKUQ8B","version":"1.0.1","page":1,"seq_no":11,"sentence":"Despite these advances, traditional human-machine inter- action (HMI) within industrial environments still presents significant challenges. Interfaces are often complex, not user-friendly, and require extensive training for operators to avoid costly errors. As previously discussed, the increasing complexity of industrial systems tends to be mirrored in their HMIs, which continue to accumulate new functions, data streams, and control mechanisms. Consequently, operators must attain ever-higher levels of specialization to interact effectively with these systems. Without support from more intuitive interaction models and an AI-driven abstraction layer, managing vast amounts of data and monitoring multi- ple subsystems simultaneously becomes nearly unfeasible.","type":"sentence","text_location":{"location":[[303,155,549,72]],"location_raw":[[303,686,549,769]]},"info":{}},{"id":"0RMhV6dX","version":"1.0.1","page":1,"seq_no":12,"sentence":"This work was partially supported by Coordenac¸a˜o de Aperfei¸coamento de Pessoal de Nı´vel Superior - Brasil (CAPES) – Financial Code 001, by Fundac¸˜ao de Amparo `a Pesquisa do Estado de Sa˜o Paulo (FAPESP) - grant #2020/09838-0, and the Conselho Nacional de Desenvolvimento Cientı´fico e Tecnolo´gico (CNPq) - grant #311380/2021-2.","type":"sentence","text_location":{"location":[[46,118,292,73]],"location_raw":[[46,723,292,768]]},"info":{}},{"id":"NQQabO0h","version":"1.0.1","page":1,"seq_no":13,"sentence":"arXiv:2506.04980v1  [cs.LG]  5 Jun 2025","type":"sentence","text_location":{"location":[[15,591,37,252]],"location_raw":[[15,250,37,589]]},"info":{}},{"id":"T8lZOCHW","version":"1.0.1","page":2,"seq_no":14,"sentence":"This article aims to present LLM agents operating under an intent-based paradigm, radically simplifying HMIs and streamlining engagement with industrial processes. By shift- ing the focus from command-driven interfaces to intent-based communication, these agents are capable of interpreting user goals expressed in natural language and autonomously orchestrating the necessary actions to fulfill them. The main contributions of this article can be summarized as:","type":"sentence","text_location":{"location":[[46,719,292,626]],"location_raw":[[46,122,292,215]]},"info":{}},{"id":"BTNPP0BI","version":"1.0.1","page":2,"seq_no":1,"sentence":"A conceptual framework that leverages LLM-based agents to enable intent-driven interaction with industrial automation systems, in alignment with the principles of Industry 5.0. • A novel intention-processing pipeline that translates natural language inputs into structured, actionable in- dustrial tasks using expectations, conditions, targets, context, and information.  A practical proof of concept, based on the CMAPSS dataset [9] and Google Agent Developer Kit (ADK), demonstrating the feasibility of agentic orchestration in a predictive maintenance scenario.","type":"sentence","text_location":{"location":[[55,623,292,481]],"location_raw":[[55,218,292,360]]},"info":{}},{"id":"b36CjRN3","version":"1.0.1","page":2,"seq_no":2,"sentence":"The article is organized as follows: section II provides an overview of AI agents and Agentic AI, traditional human- machine interaction challenges, and intent-based systems. Building on this foundation, section III outlines a novel archi- tecture that places an LLM agent at the core of an intention- processing pipeline, supported by custom tools designed to interface with industrial data and systems. In the section IV, a realistic industrial scenario is presented using the CMAPSS dataset to demonstrate the feasibility and effectiveness of the proposed approach. This is followed by the section V with a discussion of the implications and benefits of intent- based agents, as well as challenges and future directions for research and development. Finally, section VI summarizes the contributions and highlights the potential of LLM-based intent systems within the context of Industry 5.0.","type":"sentence","text_location":{"location":[[46,479,292,302]],"location_raw":[[46,362,292,539]]},"info":{}},{"id":"r7of4iyi","version":"1.0.1","page":2,"seq_no":3,"sentence":"II. BACKGROUND","type":"title","text_location":{"location":[[129,296,207,285]],"location_raw":[[129,545,207,556]]},"info":{}},{"id":"NMAn77OO","version":"1.0.1","page":2,"seq_no":4,"sentence":"With the advancement of data-driven and automated solu- tions urged by Industry 4.0, particularly through machine learning (ML) and advanced data analytics, AI naturally emerges as a means to improve decision-making and enable more efficient automation, considering the human-centric approach advocated by Industry 5.0. However, the use of AI in the industrial and manufacturing context is not a novelty. The application of AI in industrial automation has been discussed in the literature since the 1970s [10], [11], initially through simpler concepts such as perceptrons. The use of AI agents in factories has been proposed since the early 1990s [12], where researchers recognized that the true value lay in the collaboration of a network of agents, including AI agents, human agents, machine systems, and sensors.","type":"sentence","text_location":{"location":[[45,281,292,115]],"location_raw":[[45,560,292,726]]},"info":{}},{"id":"mCPeOp6Z","version":"1.0.1","page":2,"seq_no":5,"sentence":"A. AI Agents vs. Agentic AI","type":"title","text_location":{"location":[[46,110,161,98]],"location_raw":[[46,731,161,743]]},"info":{}},{"id":"anMf9JSj","version":"1.0.1","page":2,"seq_no":6,"sentence":"An AI agent is a software element capable of acting autonomously for a user or system to execute tasks [13].","type":"sentence","text_location":{"location":[[45,95,291,72]],"location_raw":[[45,746,291,769]]},"info":{}},{"id":"XnmSPEoa","version":"1.0.1","page":2,"seq_no":7,"sentence":"Since the early 1990s, AI agents have been recognized as key components of intelligent automation systems, with foun- dational research highlighting the importance of distributed collaboration among human operators, machine systems, and software agents [12]. Initial implementations predominantly relied on rule-based systems and symbolic reasoning, which, while groundbreaking at the time, were limited in their adaptability to dynamic industrial environments.","type":"sentence","text_location":{"location":[[303,791,549,696]],"location_raw":[[303,50,549,145]]},"info":{}},{"id":"8JyFDkui","version":"1.0.1","page":2,"seq_no":8,"sentence":"These early AI agents, driven by the lack of computational power at the time, typically operated under strict guidelines: they required explicit instructions, handled short-term or narrowly defined tasks, responded only to direct commands, and could only be updated through manual reprogramming. As such, they were most effective in predictable, well- structured settings.","type":"sentence","text_location":{"location":[[303,695,549,613]],"location_raw":[[303,146,549,228]]},"info":{}},{"id":"lhf8PN9C","version":"1.0.1","page":2,"seq_no":9,"sentence":"Over the subsequent decades, advances in ML, neural networks, multi-agent systems, and reinforcement learning progressively enhanced the autonomy, adaptability, and scal- ability of AI agents [14]. Building on these developments, the advent of LLMs has enabled a new workflow known as Agentic AI, where agents are empowered with capabilities such as natural language understanding, reasoning, planning, and collaboration with other agents [15]. Table I shows a comparison between AI Agents and Agentic AI.","type":"sentence","text_location":{"location":[[303,612,549,505]],"location_raw":[[303,229,549,336]]},"info":{}},{"id":"JyojG4NL","version":"1.0.1","page":2,"seq_no":10,"sentence":"Unlike traditional agents, Agentic AI systems operate with minimal human intervention, pursue long-term or intent- based goals through adaptive strategies, continuously learn from experience, and make context-aware decisions, with lo- cal or external memory, that consider multiple factors simul- taneously [16], as shown in Fig. 1. These agents can interpret the semantics of natural language input and delegate tasks to sub-agents, whether Small Language Models (SLMs), other LLMs, or domain-specific tools, while operating within data- restricted environments to ensure privacy and security. In doing so, Agentic AI bridges the gap between generative AI and action-oriented execution, offering a flexible and autonomous solution for complex and evolving industrial applications [17].","type":"sentence","text_location":{"location":[[303,504,549,338]],"location_raw":[[303,337,549,503]]},"info":{}},{"id":"i4YSAaB9","version":"1.0.1","page":2,"seq_no":11,"sentence":"Some Agentic AI design patterns are emerging as blueprints for constructing intelligent agents in complex environments [18]–[21]. The most influential are:","type":"sentence","text_location":{"location":[[303,336,549,302]],"location_raw":[[303,505,549,539]]},"info":{}},{"id":"tGzATwaI","version":"1.0.1","page":2,"seq_no":12,"sentence":"ReAct (Reasoning and Acting), which integrates step- by-step reasoning with LLMs and real-time action exe- cution with tools.","type":"sentence","text_location":{"location":[[322,299,548,264]],"location_raw":[[322,542,548,577]]},"info":{}},{"id":"11yGkxUF","version":"1.0.1","page":2,"seq_no":13,"sentence":"CodeAct builds on this by enabling agents to generate and execute code on the fly, making them capable of solving technical problems or interacting with systems. Modern Tool Use structures to choose and utilize specialized tools with standard communications such as Model Context Protocol (MCP) or Agent to Agent (A2A), including external third-party tools. Self-Reflection introduces cognitive loops, allowing agents to critique and revise their past actions via learning to improve future performance. Multi-Agent workflows orchestrate collaborative or competitive interactions between multiple agents with specialized roles, promoting modularity, scalability, and emergent behavior in complex problem-solving.","type":"sentence","text_location":{"location":[[322,284,549,91]],"location_raw":[[322,557,549,750]]},"info":{}},{"id":"MsIw9kNA","version":"1.0.1","page":2,"seq_no":14,"sentence":"Agentic RAG (Retrieval-Augmented Generation) uses external knowledge bases dynamically through agents that search, evaluate, and synthesize information.","type":"sentence","text_location":{"location":[[322,95,549,72]],"location_raw":[[322,746,549,769]]},"info":{}},{"id":"rCIVOIIh","version":"1.0.1","page":3,"seq_no":15,"sentence":"<html><body><table><tr><td>Aspect</td><td>AI Agent</td><td>Agentic AI</td></tr><tr><td>Autonomy</td><td>Operates under strict human-defined rules</td><td>Acts independently with minimal humaninput</td></tr><tr><td>Instruction</td><td>Requires specific commands and step-by- step instructions</td><td>Understands and interprets high-level intents</td></tr><tr><td>Task Scope</td><td>Focused on short-term, well-defined tasks</td><td>Oriented toward long-term, dynamic, and complex goals</td></tr><tr><td>Adaptability</td><td>Limited; updates require reprogramming</td><td>Continuously learns and adapts from experience</td></tr><tr><td>Decision Making</td><td>Based on predefined logic or rules</td><td>Capable of reasoning, planning, and multi-factor decision- making</td></tr><tr><td>Environment Handling</td><td>Performs best in predictable environments</td><td>Designed to operate in uncertain and evolving environments</td></tr><tr><td>Interaction Style</td><td>Reactive to direct inputs</td><td>Proactive, capable of initiating actions and managing work- flows</td></tr><tr><td>Tool Use</td><td>Limited or static tool integration</td><td>Can autonomously select and use tools or delegate tasks to sub-agents</td></tr><tr><td>Example Technologies</td><td>Rule-based systems, symbolic AI, early ex- pert systems</td><td>LLM-based agents, multi-agent coordination, intent-based workflows</td></tr></table></body></html>","refined_sentence":"<p>| Aspect               | AI Agent                                                                 | Agentic AI                                                                 |\\n|---------------------|--------------------------------------------------------------------------|---------------------------------------------------------------------------|\\n| Autonomy            | Operates under strict human-defined rules                                | Acts independently with minimal human input                               |\\n| Instruction         | Requires specific commands and step-by-step instructions                | Understands and interprets high-level intents                              |\\n| Task Scope          | Focused on short-term, well-defined tasks                                | Oriented toward long-term, dynamic, and complex goals                     |\\n| Adaptability        | Limited; updates require reprogramming                                  | Continuously learns and adapts from experience                            |\\n| Decision Making     | Based on predefined logic or rules                                      | Capable of reasoning, planning, and multi-factor decision-making          |\\n| Environment Handling| Performs best in predictable environments                               | Designed to operate in uncertain and evolving environments               |\\n| Interaction Style   | Reactive to direct inputs                                               | Proactive, capable of initiating actions and managing workflows           |\\n| Tool Use            | Limited or static tool integration                                      | Can autonomously select and use tools or delegate tasks to sub-agents     |\\n| Example Technologies| Rule-based systems, symbolic AI, early expert systems                   | LLM-based agents, multi-agent coordination, intent-based workflows       |</p>","type":"table","text_location":{"location":[[51,765,544,624]],"location_raw":[[51,76,544,217]]},"info":{}},{"id":"3ZzqxXiK","version":"1.0.1","page":3,"seq_no":1,"sentence":"TABLE I COMPARISON BETWEEN AI AGENTS AND AGENTIC AI","type":"sentence","text_location":{"location":[[51,765,544,624]],"location_raw":[[51,76,544,217]]},"info":{}},{"id":"VXOtRv6X","version":"1.0.1","page":3,"seq_no":2,"image_detail":[{"path":"https://netmind-public-files.s3.us-west-2.amazonaws.com/4df56280d5cc4aaeb85dd1e7cecdc19b/057f023cc6f0740adc7dcc561256f2418291a5679b1fe3c807b8856562188a83.jpg","desc":""}],"type":"image","text_location":{"location":[[50,611,544,406]],"location_raw":[[50,230,544,435]]},"info":{}},{"id":"ggtZoFn4","version":"1.0.1","page":3,"seq_no":3,"sentence":"Fig. 1. Traditional AI Agent vs. Agentic AI","type":"sentence","text_location":{"location":[[50,611,544,406]],"location_raw":[[50,230,544,435]]},"info":{}},{"id":"EaJTRw2J","version":"1.0.1","page":3,"seq_no":4,"sentence":"Selecting the appropriate design pattern depends on several factors, including available computational resources, task complexity, and critical considerations such as privacy and security.","type":"sentence","text_location":{"location":[[45,350,292,303]],"location_raw":[[45,491,292,538]]},"info":{}},{"id":"g4YUMjlx","version":"1.0.1","page":3,"seq_no":5,"sentence":"B. Human-Machine Interaction","type":"title","text_location":{"location":[[46,292,175,281]],"location_raw":[[46,549,175,560]]},"info":{}},{"id":"LBquqe6f","version":"1.0.1","page":3,"seq_no":6,"sentence":"Human–Machine Interaction (HMI) focuses on developing user-friendly and efficient interfaces that enable seamless and intuitive communication between humans and machines. Achieving this requires a deep understanding of both human behavior and the functional limitations of machines.","type":"sentence","text_location":{"location":[[46,275,291,217]],"location_raw":[[46,566,291,624]]},"info":{}},{"id":"Z39v1Gf2","version":"1.0.1","page":3,"seq_no":7,"sentence":"Over time, HMI has evolved alongside technological ad- vancements. Early interfaces relied on punched cards or command-line inputs, demanding users learn specific ma- chine protocols. The advent of graphical user interfaces (GUIs) made interactions more intuitive and visually ac- cessible. Subsequent innovations, such as touchscreens and voice recognition, further personalized the experience by allowing more natural modes of input. Despite this progress, a key challenge remains: ensuring that HMIs are easy to use, transparent, and accessible to a wide range of users [22]. To address this, the integration of natural language process- ing via LLMs has emerged as a promising enhancement, allowing users to express what they want to achieve through intentions without needing deep technical knowledge of how to implement them.","type":"sentence","text_location":{"location":[[46,215,291,73]],"location_raw":[[46,626,291,768]]},"info":{}},{"id":"zMfllGqT","version":"1.0.1","page":3,"seq_no":8,"sentence":"Recent studies have explored the integration of LLMs into industrial automation systems, enhancing HMIs and enabling more adaptive control mechanisms [6], [7], [23]– [25]. These efforts align with the principles of Industry 5.0 and highlight the high potential of LLMs in managing complex industrial tasks. However, most of these works fall short of implementing intent-driven architectures, and the full potential of agentic workflows remains largely unex- ploited. Although, they provide a foundational layer upon which intent-based systems and Agentic AI can be further developed for industrial automation.","type":"sentence","text_location":{"location":[[303,329,549,199]],"location_raw":[[303,512,549,642]]},"info":{}},{"id":"VAVeqPHG","version":"1.0.1","page":3,"seq_no":9,"sentence":"C. Intent Based Systems","type":"title","text_location":{"location":[[303,185,404,174]],"location_raw":[[303,656,404,667]]},"info":{}},{"id":"dLLvMXSs","version":"1.0.1","page":3,"seq_no":10,"sentence":"Thanks to advances in computational power and the emer- gence of LLMs, a new technological concept has been en- abled: intent-based systems. Leveraging the natural language capabilities of these models, human users can interact with systems by expressing what they intend to achieve, rather than detailing step-by-step instructions on how to achieve it. This paradigm allows human operators to focus on higher- level reasoning tasks, closer to the business layer, while delegating execution to an agentic workflow, abstracting the technical layer, focusing on a parametric agnostic conversa- tion with minimal external intervention [17].","type":"sentence","text_location":{"location":[[303,167,549,73]],"location_raw":[[303,674,549,768]]},"info":{}},{"id":"7SnBeo0u","version":"1.0.1","page":4,"seq_no":11,"sentence":"The concept of intent-based systems was initially explored in the context of telecommunications networks, intent rep- resenting an evolved version of policy in the network [26]. Telecommunications is one of the most complex fields to operate in, due to the diversity of applications, tools, and vendors involved. Ensuring seamless connectivity and mobil- ity for millions of users, without noticeable interruptions or failures, is a significant challenge. To address this, a growing body of research has recently focused on the development of intent-based networking solutions.","type":"sentence","text_location":{"location":[[46,755,292,637]],"location_raw":[[46,86,292,204]]},"info":{}},{"id":"wFUdhDWS","version":"1.0.1","page":4,"seq_no":1,"sentence":"Since 2016, intent-based networks have emerged as a promising approach to automate and self-orchestrate the complex systems of telecommunications infrastructure [27]. The concept has since gained significant traction, with a search on Google Scholar yielding over 400 publications containing the exact phrase “intent-based networks.” Within the network domain, this paradigm has been explored in diverse verticals, including vehicular networks [28], [29], healthcare systems [30], and industrial automation [31], [32].","type":"sentence","text_location":{"location":[[46,636,292,529]],"location_raw":[[46,205,292,312]]},"info":{}},{"id":"CXstptSL","version":"1.0.1","page":4,"seq_no":2,"sentence":"Recent research efforts have explored the application of intent-based paradigms in industrial automation. One such approach proposed an intent-based management framework aimed at enabling end-to-end automation across industrial systems [33]. The authors extended the common intent model defined by TM Forum [34], originally designed for autonomous networks, to address the specific requirements of industrial environments. Another notable initiative introduced the use of fine-tuned LLMs to bring intent-based interaction to the shop floor, focusing on adapting these models to accurately interpret and act on industrial intents expressed in natural language [8].","type":"sentence","text_location":{"location":[[46,529,292,387]],"location_raw":[[46,312,292,454]]},"info":{}},{"id":"fCOb6qQs","version":"1.0.1","page":4,"seq_no":3,"sentence":"Although the concept of intent-based interactions in indus- trial applications is relatively recent, current implementations still lack enabling advanced workflows that fully leverage the potential of an Agentic AI architecture. The key differentiator of this perspective lies in its ability to translate high-level intentions into concrete planning and actionable tasks with LLM-based agents.","type":"sentence","text_location":{"location":[[46,386,292,303]],"location_raw":[[46,455,292,538]]},"info":{}},{"id":"ChqpskUp","version":"1.0.1","page":4,"seq_no":4,"sentence":"III. PROPOSED FRAMEWORK","type":"title","text_location":{"location":[[106,297,232,286]],"location_raw":[[106,544,232,555]]},"info":{}},{"id":"dxj3YCFp","version":"1.0.1","page":4,"seq_no":5,"sentence":"Bringing together the concepts of Agentic AI, the evolu- tion of HMI interactions, the human-centric focus of Industry 5.0, and intent-based processing, this work aims to contribute to the existing literature by advancing the state-of-the-art in industrial automation. The proposed framework is presented in Fig. 2.","type":"sentence","text_location":{"location":[[45,282,292,211]],"location_raw":[[45,559,292,630]]},"info":{}},{"id":"ScXR49OI","version":"1.0.1","page":4,"seq_no":6,"sentence":"A. Architecture","type":"title","text_location":{"location":[[46,205,108,195]],"location_raw":[[46,636,108,646]]},"info":{}},{"id":"UtOY5AL7","version":"1.0.1","page":4,"seq_no":7,"sentence":"The selected design pattern for the architecture is the multi-agent model, which enables agent cooperation while maintaining a hierarchy between a root agent, responsible for processing user intent, and sub-agents that handle interac- tions with the specific domains of the industrial application.","type":"sentence","text_location":{"location":[[45,191,292,132]],"location_raw":[[45,650,292,709]]},"info":{}},{"id":"MbViG5gX","version":"1.0.1","page":4,"seq_no":8,"sentence":"The architecture follows this workflow: initially, the user provides input in natural language, expressing business or operational intentions by focusing on the desired outcomes rather than the specific technical execution. In doing so, there is an abstraction of the intent layer from the execution layer.","type":"sentence","text_location":{"location":[[45,131,292,72]],"location_raw":[[45,710,292,769]]},"info":{}},{"id":"ZCaBOykm","version":"1.0.1","page":4,"seq_no":9,"sentence":"Once the intent is defined, the root agent processes it using an LLM, along with stored memory from previous interactions or knowledge bases such as knowledge graphs. This allows the agent to reason about the optimal plan of action and delegate tasks accordingly. The root agent is in charge of generating the action plan, including defining the steps and iterations necessary to achieve the intended outcome.","type":"sentence","text_location":{"location":[[303,791,549,697]],"location_raw":[[303,50,549,144]]},"info":{}},{"id":"6KYP1e79","version":"1.0.1","page":4,"seq_no":10,"sentence":"Following delegation by the root agent, specialized sub- agents can utilize LLMs or SLMs fine-tuned for industrial contexts to determine next steps, such as interacting with other agents or invoking tools to perform specific tasks, e.g., real-time data collection, system configuration, or sending commands to machines.","type":"sentence","text_location":{"location":[[303,696,549,626]],"location_raw":[[303,145,549,215]]},"info":{}},{"id":"exb6GIl6","version":"1.0.1","page":4,"seq_no":11,"sentence":"The set of tools provides agents with a library of possible actions to interact with the specific industrial environment. These tools are modular and can be developed according to each machine or system protocol. As a result, this set is dynamic and adaptable to the needs of a given operation or business goal. Adding a new function is straightforward due to the modular structure; once developed, the new tool can simply be made available for agent use.","type":"sentence","text_location":{"location":[[303,624,549,530]],"location_raw":[[303,217,549,311]]},"info":{}},{"id":"q1K1TQKS","version":"1.0.1","page":4,"seq_no":12,"sentence":"B. Intention Processing","type":"title","text_location":{"location":[[303,524,401,513]],"location_raw":[[303,317,401,328]]},"info":{}},{"id":"zxlCtZRT","version":"1.0.1","page":4,"seq_no":13,"sentence":"Intention processing plays a central role in the proposed framework. Based on the interpretation of the user’s natural language input, the LLM must reason and decompose the intention into several components, as shown in Table II: expectations, conditions, targets, resources, context, and information [34].","type":"sentence","text_location":{"location":[[303,509,549,438]],"location_raw":[[303,332,549,403]]},"info":{}},{"id":"67PARepP","version":"1.0.1","page":4,"seq_no":14,"sentence":"<html><body><table><tr><td>Component</td><td>Description</td></tr><tr><td>Expectations</td><td>Define what is required or expected from the system. Core elements of an intent may relate to performance, behavior, or service delivery.</td></tr><tr><td>Conditions</td><td>Logical  expressions  used to  evaluate whether an expectation is being met. Typically based on measurable criteria like performance indicators or system states. They determine the compliance status of expectations.</td></tr><tr><td>Targets</td><td>Specify the resources or entities to which the intent applies. Can be defined statically (explicit list) or dynamically (using filters or criteria).</td></tr><tr><td>Context</td><td>Provides additional information such as pri- ority, timeframes, or environmental scope. Helps interpret when and how expectations should be applied.</td></tr><tr><td>Information</td><td>Includes auxiliary data not directly useful for guiding decisions, such as customer IDs, related intents, or operational hints.</td></tr></table></body></html>","refined_sentence":"<p>| Component    | Description                                                                                                                                 |\\n|--------------|--------------------------------------------------------------------------------------------------------------------------------------------|\\n| Expectations | Define what is required or expected from the system. Core elements of an intent may relate to performance, behavior, or service delivery.     |\\n| Conditions   | Logical expressions used to evaluate whether an expectation is being met. Typically based on measurable criteria like performance indicators or system states. They determine the compliance status of expectations. |\\n| Targets      | Specify the resources or entities to which the intent applies. Can be defined statically (explicit list) or dynamically (using filters or criteria). |\\n| Context      | Provides additional information such as priority, timeframes, or environmental scope. Helps interpret when and how expectations should be applied. |\\n| Information  | Includes auxiliary data not directly useful for guiding decisions, such as customer IDs, related intents, or operational hints.                |</p>","type":"table","text_location":{"location":[[302,401,549,165]],"location_raw":[[302,440,549,676]]},"info":{}},{"id":"iuova2Qr","version":"1.0.1","page":4,"seq_no":15,"sentence":"TABLE II KEY COMPONENTS OF INTENTION PROCESSING","type":"sentence","text_location":{"location":[[302,401,549,165]],"location_raw":[[302,440,549,676]]},"info":{}},{"id":"YVLEu6xv","version":"1.0.1","page":4,"seq_no":16,"sentence":"With this decomposition, it is possible to make an exe- cution plan to achieve the desired expectations to the ap- propriate targets, without risk of non-compliance according to conditions, context, and information. The root agent can decide whether to use specialized sub-agents to conclude its tasks or not; eventually, in some architectures, the root agent can call tools directly.","type":"sentence","text_location":{"location":[[303,155,549,72]],"location_raw":[[303,686,549,769]]},"info":{}},{"id":"NMIQYdOQ","version":"1.0.1","page":5,"seq_no":17,"image_detail":[{"path":"https://netmind-public-files.s3.us-west-2.amazonaws.com/4df56280d5cc4aaeb85dd1e7cecdc19b/9cdb9c3d38b59e5017f2754ad52170bba2a084f666f98a07d0ffdc6fc5e85cee.jpg","desc":""}],"type":"image","text_location":{"location":[[50,769,548,572]],"location_raw":[[50,72,548,269]]},"info":{}},{"id":"eEev0rZK","version":"1.0.1","page":5,"seq_no":1,"sentence":"INTENT-BASED AGENTIC AI FRAMEWORK Fig. 2. Proposed framework for Industry 5.0 applying intent-based and Agentic AI.","type":"sentence","text_location":{"location":[[50,769,548,572]],"location_raw":[[50,72,548,269]]},"info":{}},{"id":"wmEX3xi0","version":"1.0.1","page":5,"seq_no":2,"sentence":"C. Sub-agents","type":"title","text_location":{"location":[[46,525,104,514]],"location_raw":[[46,316,104,327]]},"info":{}},{"id":"aG4DcorO","version":"1.0.1","page":5,"seq_no":3,"sentence":"Based on the plan decomposed by the root agent, sub- agents may be triggered to carry out specific tasks or retrieve the required information. These sub-agents can take various forms, including other LLM-based agents, smaller and more specialized SLM agents, or even non-LLM-based agents tai- lored for domain-specific operations or system orchestration.","type":"sentence","text_location":{"location":[[46,508,291,437]],"location_raw":[[46,333,291,404]]},"info":{}},{"id":"oN93PNwY","version":"1.0.1","page":5,"seq_no":4,"sentence":"The structure of the agentic workflow can vary depending on the application context. Agent interactions may follow different patterns, such as iterative loops until predefined criteria are met, sequential delegation of tasks, or parallel execution to enhance performance and responsiveness.","type":"sentence","text_location":{"location":[[46,435,291,377]],"location_raw":[[46,406,291,464]]},"info":{}},{"id":"j9aO3oyt","version":"1.0.1","page":5,"seq_no":5,"sentence":"With more specialized context and targeted instructions, sub-agents can address tasks more effectively to achieve the desired outcomes. They have access to a defined set of tools, and since each tool includes well-described input/output specifications, sub-agents can autonomously select the most appropriate tool for the task at hand.","type":"sentence","text_location":{"location":[[46,375,292,305]],"location_raw":[[46,466,292,536]]},"info":{}},{"id":"MIEMfGSt","version":"1.0.1","page":5,"seq_no":6,"sentence":"D. Custom Tools","type":"title","text_location":{"location":[[46,292,116,281]],"location_raw":[[46,549,116,560]]},"info":{}},{"id":"DNC30pM8","version":"1.0.1","page":5,"seq_no":7,"sentence":"Tools are modular components that extend the agent’s ability to interact programmatically with external systems, execute tasks, and retrieve or process information beyond its internal reasoning capabilities. These tools function as callable units, such as code functions, API connectors, or simulation interfaces, that the agent can dynamically select and invoke during task execution. Tools do not reason on their own; instead, the root agent’s LLM determines which tool to use and provides the appropriate input.","type":"sentence","text_location":{"location":[[46,275,291,168]],"location_raw":[[46,566,291,673]]},"info":{}},{"id":"XF2cwZnj","version":"1.0.1","page":5,"seq_no":8,"sentence":"The process by which agents use the tools is dynamic and structured. According to the agent’s input, the appropriate tool is selected based on its description, invoked with gener- ated arguments, observing the output, and incorporating the result into further decision making. This allows agents to link multiple tools together or repeat operations based on conditions, making them highly adaptable and effective for completing complex tasks using intent-driven workflows.","type":"sentence","text_location":{"location":[[46,167,291,72]],"location_raw":[[46,674,291,769]]},"info":{}},{"id":"lEigfKMJ","version":"1.0.1","page":5,"seq_no":9,"sentence":"Different types of tools support varying operational needs, including custom-defined functions, built-in utilities, such as search or code execution, long-running asynchronous tools, and integrations with third-party libraries. To ensure effectiveness, tools must have clear function names and descriptions, and instructions should specify how the agent should respond to different outcomes, handling errors, or combining tools in sequence. In industrial environments, this allows agents to interact with real-time data sources or control machines, enabling actions that would not be possible through agents based on language models alone.","type":"sentence","text_location":{"location":[[303,525,549,394]],"location_raw":[[303,316,549,447]]},"info":{}},{"id":"zG8kIg7f","version":"1.0.1","page":5,"seq_no":10,"sentence":"IV. PROOF OF CONCEPT","type":"title","text_location":{"location":[[374,386,478,375]],"location_raw":[[374,455,478,466]]},"info":{}},{"id":"oZVUDz5J","version":"1.0.1","page":5,"seq_no":11,"sentence":"A proof of concept (PoC) is proposed to validate the aforementioned framework. Using the well-known industrial dataset CMAPSS and Python’s open-source libraries, the objective is to develop a reproducible blueprint for applying Agentic AI in industrial environments.","type":"sentence","text_location":{"location":[[303,370,549,311]],"location_raw":[[303,471,549,530]]},"info":{}},{"id":"wm7Tqz77","version":"1.0.1","page":5,"seq_no":12,"sentence":"The prototype focuses on integrating intent-based interac- tion, an LLM-based root agent for reasoning and planning, and specialized sub-agents capable of orchestrating domain- specific tasks such as diagnostics, data querying, and main- tenance planning. This PoC aims not only to demonstrate technical feasibility but also to provide insights into archi- tectural patterns, workflow orchestration, and tool integration strategies for agent-based industrial systems. Ultimately, the project lays the groundwork for future research and devel- opment of intelligent, adaptive, and intent-driven automation aligned with the principles of Industry 5.0.","type":"sentence","text_location":{"location":[[303,309,549,179]],"location_raw":[[303,532,549,662]]},"info":{}},{"id":"oaDHENAo","version":"1.0.1","page":5,"seq_no":13,"sentence":"A. Dataset","type":"title","text_location":{"location":[[303,170,348,160]],"location_raw":[[303,671,348,681]]},"info":{}},{"id":"ut3Zj6Fv","version":"1.0.1","page":5,"seq_no":14,"sentence":"The CMAPSS [9] is an industrial, well-known, synthetic dataset used to train and test predictions of remaining useful life (RUL). It was created by a simulation tool of the same name (Commercial Modular Aero-Propulsion System Simulation) coded in MATLAB® and Simulink®.","type":"sentence","text_location":{"location":[[303,155,549,97]],"location_raw":[[303,686,549,744]]},"info":{}},{"id":"E1yxmLjo","version":"1.0.1","page":5,"seq_no":15,"sentence":"Each line of the dataset contains an instance of an engine represented by a set of measurements, including three opera- tional settings and 21 sensor readings collected at each cycle. The primary prediction objective is to estimate the RUL, the number of cycles remaining before the engine reaches failure. Table III shows a list of parameters and their units [35].","type":"sentence","text_location":{"location":[[303,95,549,72]],"location_raw":[[303,746,549,769]]},"info":{}},{"id":"DkKT3Zwl","version":"1.0.1","page":6,"seq_no":16,"sentence":"<html><body><table><tr><td>Attribute</td><td>Unit</td><td>Type</td></tr><tr><td>Engine ID Cycle</td><td></td><td>Index</td></tr><tr><td>Speed Altitude Sea level temperature Fan inlet temperature</td><td>Ma feet °F R</td><td>Operational Setting</td></tr><tr><td>LPC outlet temperature HPC outlet temperature LPT outlet temperature Fan inlet pressure Bypass-duct pressure HPC outlet pressure Physical fan speed Physical core speed Engine pressure ratio HPC outlet static pressure Ratio of fuel flow Corrected fan speed Corrected core speed Bypass ratio</td><td>°R R °R psia rpm rpm psia pps/psia rpm rpm psia psia</td><td>Sensor</td></tr></table></body></html>","refined_sentence":"<p>| Attribute                          | Unit         | Type             |\\n|-----------------------------------|--------------|------------------|\\n| Engine ID Cycle                   |              | Index            |\\n| Speed                             | Ma feet °F   | Operational Setting |\\n| Sea level temperature             | °F           |                  |\\n| Fan inlet pressure                | °R           | Sensor           |\\n| LPC outlet temperature            | °R           |                  |\\n| HPC outlet temperature            | °R           |                  |\\n| LPT outlet temperature            | °R           |                  |\\n| Fan inlet pressure                | psia         |                  |\\n| Bypass-duct pressure              | psia         |                  |\\n| HPC outlet pressure               | psia         |                  |\\n| Physical fan speed                | rpm          |                  |\\n| Physical core speed               | rpm          |                  |\\n| Engine pressure ratio             | -            |                  |\\n| HPC outlet static pressure        | psia         |                  |\\n| Ratio of fuel flow                | pps/psia     |                  |\\n| Corrected fan speed               | rpm          |                  |\\n| Corrected core speed              | rpm          |                  |\\n| Bypass ratio                      | -            |                  |\\n| Burner fuel-air ratio             | -            |                  |\\n| Bleed enthalpy                    | -            |                  |\\n| Required fan speed                | rpm          |                  |\\n| Required fan conversion speed     | rpm          |                  |\\n| High-pressure turbines cool air flow | lbm/s   |                  |\\n| Low-pressure turbines cool air flow | lbm/s   |                  |</p>","type":"table","text_location":{"location":[[46,703,291,456]],"location_raw":[[46,138,291,385]]},"info":{}},{"id":"Bp0zEQdS","version":"1.0.1","page":6,"seq_no":1,"sentence":"TABLE III CMAPSS DATASET ATTRIBUTES","type":"sentence","text_location":{"location":[[46,703,291,456]],"location_raw":[[46,138,291,385]]},"info":{}},{"id":"61097eD4","version":"1.0.1","page":6,"seq_no":2,"sentence":"Widely used in the development and evaluation of Prog- nostics and Health Management (PHM) models for predictive maintenance, the dataset has become a benchmark in the field, with over 3,000 academic articles referencing it on Google Scholar. However, in the context of this work, the dataset is not used for predictive modeling. Instead, it serves as a structured and realistic source of industrial data to demonstrate the system’s ability to interact with a dynamic environment and execute agentic workflows.","type":"sentence","text_location":{"location":[[46,443,292,336]],"location_raw":[[46,398,292,505]]},"info":{}},{"id":"fQdwzRNU","version":"1.0.1","page":6,"seq_no":3,"sentence":"B. Implementation","type":"title","text_location":{"location":[[46,320,122,309]],"location_raw":[[46,521,122,532]]},"info":{}},{"id":"JsSkgKUr","version":"1.0.1","page":6,"seq_no":4,"sentence":"Several libraries have gained traction in both industry and academia for the implementation of Agentic AI systems, including LangChain1, CrewAI2, and Smolagents3. For this project, the recently released Google  \\mathrm{\\ADK^{4}}  was selected. The choice was motivated by its flexible orchestration capa- bilities via AutoFlow, native integration with Gemini5 (free tier of Gemini 2.0 Flash), and a built-in web interface that eliminates the need to develop a front-end from scratch. Additionally, GitHub Codespaces6 was used as the execution environment, provisioning a cloud-based virtual machine with 2 CPU cores, 8 GB of RAM, and 32\\mathrm{\\GB}  of storage.","type":"sentence","text_location":{"location":[[46,302,292,171]],"location_raw":[[46,539,292,670]]},"info":{}},{"id":"NqDQAoEd","version":"1.0.1","page":6,"seq_no":5,"sentence":"To reduce complexity and avoid excessive agent calls, a controlled subset of the CMAPSS dataset was used, contain-","type":"sentence","text_location":{"location":[[45,169,292,146]],"location_raw":[[45,672,292,695]]},"info":{}},{"id":"gciPyDXW","version":"1.0.1","page":6,"seq_no":6,"sentence":"1https://www.langchain.com/ 2https://www.crewai.com/ 3https://smolagents.org/ 4https://google.github.io/adk-docs/ 5https://ai.google.dev/gemini-api/docs 6https://github.com/features/codespaces","type":"sentence","text_location":{"location":[[53,132,181,72]],"location_raw":[[53,709,181,769]]},"info":{}},{"id":"d0HThFgR","version":"1.0.1","page":6,"seq_no":7,"sentence":"ing 20 engines. The code, available on  \\mathrm{GitHub}^{7} , performs a multi-agent architecture as illustrated in Figure 3.","type":"sentence","text_location":{"location":[[302,792,550,768]],"location_raw":[[302,49,550,73]]},"info":{}},{"id":"XOYsbAuf","version":"1.0.1","page":6,"seq_no":8,"image_detail":[{"path":"https://netmind-public-files.s3.us-west-2.amazonaws.com/4df56280d5cc4aaeb85dd1e7cecdc19b/a7fccc693bb036e61416c21d70d28d1542218402753c245444382051bdc6db1b.jpg","desc":""}],"type":"image","text_location":{"location":[[304,755,549,626]],"location_raw":[[304,86,549,215]]},"info":{}},{"id":"66Xm0pQL","version":"1.0.1","page":6,"seq_no":9,"sentence":"Fig. 3. Agentic AI implementation with Google ADK.","type":"sentence","text_location":{"location":[[304,755,549,626]],"location_raw":[[304,86,549,215]]},"info":{}},{"id":"BbWY7TTU","version":"1.0.1","page":6,"seq_no":10,"sentence":"A root_agent first decomposes the user’s intent into the core components: Expectations, Conditions, Targets, Context and Information. After reasoning and planning, it can delegate tasks to two specialized sub-agents defined for this PoC:","type":"sentence","text_location":{"location":[[302,595,549,536]],"location_raw":[[302,246,549,305]]},"info":{}},{"id":"VmgBAz7D","version":"1.0.1","page":6,"seq_no":11,"sentence":"• data_agent: Retrieves engine telemetry and provides RUL predictions. In this PoC, RUL values are taken directly from the dataset (ground truth), since predic- tive modeling is outside of the current scope. It has access to the tools get_engine_data_json and predict_engine_rul.  maintenance_agent: Identifies engines near failure and plans preventive maintenance: scheduling down- time, assigning teams, and estimating per-engine work- load. It has the following tools available to invoke:","type":"sentence","text_location":{"location":[[312,533,549,414]],"location_raw":[[312,308,549,427]]},"info":{}},{"id":"Iy8s4hb3","version":"1.0.1","page":6,"seq_no":12,"sentence":"– suggest_maintenance_action – estimate_maintenance_cost – assign_maintenance_staff – schedule_maintenance_task","type":"sentence","text_location":{"location":[[329,410,497,364]],"location_raw":[[329,431,497,477]]},"info":{}},{"id":"J7yKFluA","version":"1.0.1","page":6,"seq_no":13,"sentence":"Upon receiving outputs from the data_agent, the root_agent autonomously decides whether to invoke the maintenance_agent for preventive action or to initiate a shutdown of critical engines by invoking the stop_engine tool directly. The root_agent also returns the results as a structured table summary, including all stops and mainte- nance schedules.","type":"sentence","text_location":{"location":[[303,361,549,278]],"location_raw":[[303,480,549,563]]},"info":{}},{"id":"5jDBtFNF","version":"1.0.1","page":6,"seq_no":14,"sentence":"C. Results","type":"title","text_location":{"location":[[303,270,347,259]],"location_raw":[[303,571,347,582]]},"info":{}},{"id":"lJwM0eAi","version":"1.0.1","page":6,"seq_no":15,"sentence":"To validate the system’s ability to decompose high-level intentions into actionable steps, the following initial prompt was submitted to the agent, without any prior context:","type":"sentence","text_location":{"location":[[303,254,549,219]],"location_raw":[[303,587,549,622]]},"info":{}},{"id":"GAxU1B06","version":"1.0.1","page":6,"seq_no":16,"sentence":"”I need to maintain all engines working well according to their predicted RUL, avoiding unex- pected stops, please make a consolidated predictive maintenance plan in a table format.”","type":"sentence","text_location":{"location":[[322,217,530,169]],"location_raw":[[322,624,530,672]]},"info":{}},{"id":"YvKm45Nl","version":"1.0.1","page":6,"seq_no":17,"sentence":"Based on this input, asking for the root_agent how it processed the intent and structured it, it answered that it decomposed into the following components:","type":"sentence","text_location":{"location":[[302,166,549,131]],"location_raw":[[302,675,549,710]]},"info":{}},{"id":"1rC0ktQR","version":"1.0.1","page":6,"seq_no":18,"sentence":"• Expectation: Maintain all engines in optimal operating condition to prevent unexpected failures. This was in- ferred from the phrase “maintain all the engines working","type":"sentence","text_location":{"location":[[312,128,549,93]],"location_raw":[[312,713,549,748]]},"info":{}},{"id":"n86EfHbf","version":"1.0.1","page":6,"seq_no":19,"sentence":"7https://github.com/RomeroCode/talk-to-your-factory well according to their predicted RUL, avoiding un- expected stops,” implying continuous, reliable engine performance.","type":"sentence","text_location":{"location":[[311,82,483,73]],"location_raw":[[311,759,483,768]]},"info":{}},{"id":"4UbAD2AS","version":"1.0.1","page":7,"seq_no":20,"sentence":"Targets: All 20 engines in the fleet. The request for a consolidated plan covering “all the engines” indicates that the intent applies to the entire fleet under manage- ment.  Conditions: RUL must be above a critical threshold, as defined by the maintenance_agent. This stems from the clause “according to their predicted RUL,” which implies that engines with RULs below the thresh- old should be prioritized for maintenance.  Context: High-priority, proactive maintenance strategy aimed at minimizing unplanned downtime and maximiz- ing engine lifespan. The phrasing of the request reflects a strategic and preventative approach.  Information: Predicted RUL values and engine sensor data, obtained from the data_agent, are required to evaluate each engine’s condition and inform decision- making.","type":"sentence","text_location":{"location":[[54,758,292,552]],"location_raw":[[54,83,292,289]]},"info":{}},{"id":"Bz8n40n4","version":"1.0.1","page":7,"seq_no":1,"sentence":"Based on this decomposition, the agentic system per- formed a coordinated reasoning process between agents, evaluated the statuses of the engine, and generated a pre- dictive maintenance plan. The final output of the system, de- tailing the actions to be taken for each engine, is summarized in Table IV.","type":"sentence","text_location":{"location":[[46,548,291,478]],"location_raw":[[46,293,291,363]]},"info":{}},{"id":"Os8mSsfA","version":"1.0.1","page":7,"seq_no":2,"sentence":"Additional tests were conducted in which multiple data points were queried, without requiring any operator’s previ- ous knowledge of engine protocols or operational manuals. The system responded correctly, demonstrating the usability and accessibility of an intent-based approach. This reinforces the potential of such systems to simplify human–machine interaction, allowing operators to focus on higher-level tasks that require business insight, strategic decision-making, or creative problem-solving.","type":"sentence","text_location":{"location":[[46,476,292,369]],"location_raw":[[46,365,292,472]]},"info":{}},{"id":"Ph2Pymii","version":"1.0.1","page":7,"seq_no":3,"sentence":"V. DISCUSSION","type":"title","text_location":{"location":[[135,355,202,344]],"location_raw":[[135,486,202,497]]},"info":{}},{"id":"1lhMbJ0T","version":"1.0.1","page":7,"seq_no":4,"sentence":"Through natural language input, abstracting away technical complexity and aligning more closely with business needs, it was possible to successfully decompose an intent-based request into a concrete action plan to be delegated to special- ized sub-agents. These sub-agents, equipped with modular tools adapted to the specific application domain, executed the tasks received from the root_agent and returned outputs used to advance the planned workflow. This result fulfills the objective of simplifying the HMI and reinforces the human-centered approach promoted by Industry 5.0 and the United Nations SDGs, ensuring that the growing technical complexity of systems does not become a justification for replacing human labor with machines and AI.","type":"sentence","text_location":{"location":[[46,335,291,181]],"location_raw":[[46,506,291,660]]},"info":{}},{"id":"lH1DLHrn","version":"1.0.1","page":7,"seq_no":5,"sentence":"The presented PoC and the underlying framework demon- strate the potential of Agentic AI in industrial automation. There remains a significant opportunity for further explo- ration, particularly through the integration of external sub- agents and tools to expand the range of actionable tasks in industrial contexts. The combination of the versatility of multi-agent systems with the conversational and associative power of LLMs points the way for innovative applications. These range from revisiting legacy concepts that were once constrained by limited technology to proposing entirely new and disruptive methods for various sectors of the industry.","type":"sentence","text_location":{"location":[[46,179,291,72]],"location_raw":[[46,662,291,769]]},"info":{}},{"id":"AXvN1yq4","version":"1.0.1","page":7,"seq_no":6,"sentence":"Despite the enthusiasm, several challenges must be ad- dressed before Agentic AI systems can be deployed at scale in production environments. These include concerns over information security, data privacy, energy expendi- tures, explainability of AI decisions, hallucination control, consistency and predictability of actions, effective prompt engineering, and, most critically, the quality of the under- lying data. Overcoming these challenges will be essential to building trust and ensuring the reliability of Agentic AI in industrial applications. For example, in the context of security, some agentic architectures are already incorporating guardrail techniques to prevent sensitive information from leaking to external servers, helping enforce data boundaries and maintain compliance.","type":"sentence","text_location":{"location":[[303,767,549,601]],"location_raw":[[303,74,549,240]]},"info":{}},{"id":"z2qlqz5p","version":"1.0.1","page":7,"seq_no":7,"sentence":"In future work, additional tests will be necessary to evolve the current PoC into a production-ready system. The use of real-world datasets and implementation in actual industrial environments will be essential to validate the framework and uncover any limitations. Alternative LLM architectures may also be explored, as well as fine-tuned SLMs specifically adapted for industrial automation contexts. As research and experimentation progress, benchmarking methodologies can be applied to evaluate system performance, accuracy, and the benefits brought by Agentic AI in real-world applications.","type":"sentence","text_location":{"location":[[303,600,549,481]],"location_raw":[[303,241,549,360]]},"info":{}},{"id":"v5WJ4MxI","version":"1.0.1","page":7,"seq_no":8,"sentence":"VI. CONCLUSION","type":"title","text_location":{"location":[[388,471,464,461]],"location_raw":[[388,370,464,380]]},"info":{}},{"id":"TzY0XvPA","version":"1.0.1","page":7,"seq_no":9,"sentence":"Although artificial intelligence has been a topic in indus- trial automation since the 1970s, and the use of AI agents has been reported since the 1990s, only now unprecedented computational power is available. Across all sectors, there is a growing trend to revisit legacy ideas once abandoned due to technical limitations. With the advent of Agentic AI, many of these ideas can now be approached with renewed potential and more promising results. Innovation alone does not drive adoption, but tangible benefits such as improved productivity, human dignity, and cost efficiency do.","type":"sentence","text_location":{"location":[[303,455,549,336]],"location_raw":[[303,386,549,505]]},"info":{}},{"id":"v1MUbbXL","version":"1.0.1","page":7,"seq_no":10,"sentence":"This work demonstrates that it is possible to integrate AI in alignment with the three core pillars of Industry 5.0: a human-centric approach, sustainability, and resilience. By bringing industrial automation management and HMI closer to natural language, capable not only of understanding intent- based communication but also of planning actions using available tools, a new range of possibilities emerges. This enables human operators to focus on tasks requiring critical thinking and creativity, while delegating routine technical operations to an Agentic AI system. In doing so, humans concentrate on high-level objectives aligned with business goals, while the agentic system handles the technical layer.","type":"sentence","text_location":{"location":[[303,334,549,193]],"location_raw":[[303,507,549,648]]},"info":{}},{"id":"bZZlYsN2","version":"1.0.1","page":7,"seq_no":11,"sentence":"Naturally, any emerging technology faces limitations. In the case of LLM-based agentic systems, prompt engineering becomes a critical factor. During testing, a certain sensitivity to prompt phrasing was observed, and small changes often led to different outcomes, highlighting the challenge of achieving predictability and consistency. In addition, the explainability problem is present in every AI application. Finally, data quality remains a concern, covering aspects such as reliability, accuracy, privacy, and trust. Addressing these challenges will be vital for large-scale deployment.","type":"sentence","text_location":{"location":[[303,191,549,73]],"location_raw":[[303,650,549,768]]},"info":{}},{"id":"CYF0AL1P","version":"1.0.1","page":8,"seq_no":12,"sentence":"<html><body><table><tr><td>#Engines</td><td>RUL Range</td><td>Recommended Action</td><td>Priority</td><td>Cost (USD)</td><td>Labor Hours</td><td>Assigned Staff</td><td>Scheduled Time</td></tr><tr><td>15</td><td>82-124</td><td>MONITOR</td><td>low</td><td>0</td><td>0</td><td>[jr_mechanic]</td><td>Within 7 days</td></tr><tr><td>1</td><td>69</td><td>MONITOR</td><td>low</td><td>0</td><td>0</td><td>[jr_mechanic]</td><td>Within 3 days</td></tr><tr><td>2</td><td>28,50</td><td>REPAIR</td><td>high</td><td>6000</td><td>4</td><td>[mechanic, jr_mechanic]</td><td>Within 3 days</td></tr><tr><td>１</td><td>16</td><td>STOP</td><td>critical</td><td>15000</td><td>8</td><td>[tech_lead, sr_mechanic]</td><td>IMMEDIATE</td></tr></table></body></html>","refined_sentence":"<p>| # Engines | RUL Range   | Recommended Action | Priority | Cost (USD) | Labor Hours | Assigned Staff                  | Scheduled Time |\\n|-----------|-------------|--------------------|----------|------------|-------------|----------------------------------|----------------|\\n| 15        | 82-124      | MONITOR            | low      | 0          | 0           | [jr_mechanic]                    | Within 7 days  |\\n| 1         | 69          | MONITOR            | low      | 0          | 0           | [jr_mechanic]                    | Within 3 days  |\\n| 2         | 28, 50      | REPAIR             | high     | 6000       | 4           | [mechanic, jr_mechanic]          | Within 3 days  |\\n| 1         | 16          | STOP               | critical | 15000      | 8           | [tech_lead, sr_mechanic]         | IMMEDIATE      |</p>","type":"table","text_location":{"location":[[48,764,550,706]],"location_raw":[[48,77,550,135]]},"info":{}},{"id":"SQMMOhxb","version":"1.0.1","page":8,"seq_no":1,"sentence":"TABLE IV SUMMARY OF ENGINE MAINTENANCE ACTIONS","type":"sentence","text_location":{"location":[[48,764,550,706]],"location_raw":[[48,77,550,135]]},"info":{}},{"id":"F2VnOjIs","version":"1.0.1","page":8,"seq_no":2,"sentence":"Future work can build upon this paper’s important mile- stone in intent-based communication research through Agen- tic AI systems. With the continued momentum and en- thusiasm around AI technologies, innovation is advancing rapidly and it is certain that new tools and techniques will soon emerge, bringing increasingly precise solutions to the advancement of industry.","type":"sentence","text_location":{"location":[[46,685,292,602]],"location_raw":[[46,156,292,239]]},"info":{}},{"id":"mF4d8mlz","version":"1.0.1","page":8,"seq_no":3,"sentence":"REFERENCES","type":"title","text_location":{"location":[[140,593,197,582]],"location_raw":[[140,248,197,259]]},"info":{}},{"id":"0bqavCJ7","version":"1.0.1","page":8,"seq_no":4,"sentence":"[1] ABI Research, “Industrial data generation forecast,” Sep 2024. [On- line] Available on: https://www.abiresearch.com/news-resources/chart- data/manufacturing-industry-amount-of-data-generated. [2] M. Passalacqua, R. Pellerin, F. Magnani, P. Doyon-Poulin, L. Del- Aguila, J. Boasen, and P.-M. L´eger, “Human-centred ai in industry 5.0: a systematic review,” International Journal of Production Research, vol. 63, no. 7, pp. 2638–2669, 2025. [3] D. Romero, J. Stahre, T. Wuest, O. Noran, P. Bernus, A. Fasth, Fast- Berglund, and D. Gorecky, “Towards an operator 4.0 typology: A human-centric perspective on the fourth industrial revolution technolo- gies,” 10 2016. [4] E. Commission, D.-G. for Research, Innovation, M. Breque, L. De Nul, and A. Petridis, Industry 5.0 – Towards a sustainable, human-centric and resilient European industry. Publications Office of the European Union, 2021. [5] M. A. Hassan, S. Zardari, M. U. Farooq, M. M. Alansari, and S. A. Nagro, “Systematic analysis of risks in industry 5.0 architecture,” Applied Sciences, vol. 14, no. 4, p. 1466, 2024. [6] R. Figli`e, T. Turchi, G. Baldi, and D. Mazzei, “Towards an llm- based intelligent assistant for industry 5.0,” in Proceedings of the 1st International Workshop on Designing and Building Hybrid Human–AI Systems (SYNERGY 2024), vol. 3701, 2024. [7] J. Lim, B. Vogel-Heuser, and I. Kovalenko, “Large language model- enabled multi-agent manufacturing systems,” in 2024 IEEE 20th International Conference on Automation Science and Engineering (CASE), pp. 3940–3946, IEEE, 2024. [8] E. Zeydan, J. Mangues, S. S. Arslan, Y. Turk, and M. Liyanage, “Gen- erative artificial intelligence for intent-based industrial automation,” IEEE Consumer Electronics Magazine, 2024. [9] A. Saxena, K. Goebel, D. Simon, and N. Eklund, “Damage propagation modeling for aircraft engine run-to-failure simulation,” in 2008 inter- national conference on prognostics and health management, pp. 1–9, IEEE, 2008. [10] Nitzan, “Programmable industrial automation,” IEEE Transactions on Computers, vol. 100, no. 12, pp. 1259–1270, 1976. [11] M. Minsky, “Automation and artificial intelligence,” Science, Technol- ogy, and the Modern Navy: Thirtieth Anniversary, 1946-1976, vol. 37, p. 111, 1976. [12] B. Chandrasekaran and F. Coyle, “Aaai’90,” IEEE Intelligent Systems, vol. 5, no. 05, pp. 10–12, 1990. [13] A. Bawcom, N. von Bismarck, A. Tavakoli, H. Harreis, C. Giovine, J. Kaplan, K. Rowshankish, J. Amar, L. Yee, M. Chui, R. Roberts, L. H¨am¨ala¨inen, L. Lerner, R. Thomas, and V. Chung, “What is an ai agent?,” tech. rep., McKinsey & Company, Mar 2025. [Online] Available on: https://www.mckinsey.com/featured-insights/mckinsey- explainers/what-is-an-ai-agent/. [14] S. Tzafestas and H. Verbruggen, Artificial intelligence in industrial decision making, control, and automation: an introduction. Springer, 1995. [15] M. A. Ferrag, N. Tihanyi, and M. Debbah, “From llm reasoning to autonomous ai agents: A comprehensive review,” arXiv preprint arXiv:2504.19678, 2025. [16] L. Hughes, Y. K. Dwivedi, T. Malik, M. Shawosh, M. A. Albashrawi, I. Jeon, V. Dutot, M. Appanderanda, T. Crick, R. De’, et al., “Ai agents and agentic systems: A multi-expert analysis,” Journal of Computer Information Systems, pp. 1–29, 2025. [17] D. B. Acharya, K. Kuppan, and B. Divya, “Agentic ai: Autonomous intelligence for complex goals–a comprehensive survey,” IEEE Access, 2025. [18] P. D. Rashmiranjan, “Empirical analysis of agentic ai design patterns in real-world applications,” International Journal of Innovative Re- search in Computer and Communication Engineering, vol. 13, no. 4, pp. 9761–9769, 2025. [19] F. Bousetouane, “Agentic systems: A guide to transforming industries with vertical ai agents,” arXiv preprint arXiv:2501.00881, 2025. [20] G. d. A. e Aquino, N. d. S. de Azevedo, L. Y. S. Okimoto, L. Y. S. Camelo, H. L. de Souza Bragan¸ca, R. Fernandes, A. Printes, F. Car- doso, R. Gomes, and I. G. Torne´, “From rag to multi-agent systems: A survey of modern approaches in llm development,” 2025. [21] P. Bornet, J. Wirtz, T. H. Davenport, D. De Cremer, B. Evergreen, P. Fersht, R. Gohel, S. Khiyara, P. Sund, and N. Mullakara, Agentic Artificial Intelligence: Harnessing AI Agents to Reinvent Business, Work and Life. Irreplaceable Publishing, 2025. [22] D. Mourtzis, J. Angelopoulos, and N. Panopoulos, “The future of the human–machine interface (hmi) in society 5.0,” Future Internet, vol. 15, no. 5, p. 162, 2023. [23] P. K. Gantayat, T. Kaur, M. Majhi, U. K. Jena, S. Das, et al., “From efficiency to innovation: Llm 5.0 and the future of industry,” in 2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI), pp. 551–558, IEEE, 2025. [24] Z. Keskin, D. Joosten, N. Klasen, M. Huber, C. Liu, B. Drescher, and R. H. Schmitt, “Llm-enhanced human-machine interaction for adaptive decision making in dynamic manufacturing process environments,” IEEE access, 2025. [25] B. R. Brown, “Human–machine teaming using large language models,” in Interdependent Human-Machine Teams, pp. 41–66, Elsevier, 2025. [26] E. Zeydan and Y. Turk, “Recent advances in intent-based networking: A survey,” in 2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring), pp. 1–5, IEEE, 2020. [27] D. Schulz, “Intent-based automation networks: Toward a common reference model for the self-orchestration of industrial intranets,” in IECON 2016-42nd Annual Conference of the IEEE Industrial Electronics Society, pp. 4657–4664, IEEE, 2016. [28] Y. Shen, Y. Ahn, M. Gu, and J. P. Jeong, “Intent-based management for software-defined vehicles in intelligent transportation systems,” in 2024 IEEE 10th International Conference on Network Softwarization (NetSoft), pp. 1–6, IEEE, 2024. [29] S. Safavat and D. B. Rawat, “On the elliptic curve cryptography for privacy-aware secure aco-aodv routing in intent-based internet of vehi- cles for smart cities,” IEEE Transactions on Intelligent Transportation Systems, vol. 22, no. 8, pp. 5050–5059, 2020. [30] Y. Njah, A. Leivadeas, J. Violos, and M. Falkner, “Toward intent- based network automation for smart environments: A healthcare 4.0 use case,” IEEE Access, vol. 11, pp. 136565–136576, 2023. [31] E. Tomur, Z. Bilgin, U. G¨ulen, E. U. Soykan, L. Karac¸ay, and F. Karako¸c, “Intent-based security for functional safety in cyber- physical systems,” IEEE Transactions on Emerging Topics in Com- puting, 2023. [32] R. F. Ustok, A. C. Baktir, and E. D. Biyar, “Asset administration shell as an enabler of intent-based networks for industry 4.0 automation,” in 2022 IEEE 27th International Conference on Emerging Technologies and Factory Automation (ETFA), pp. 1–8, IEEE, 2022. [33] A. C. Baktir and E. D. Biyar, “Intent-based management for industrial automation,” in 2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA), pp. 1–4, IEEE, 2024. [34] Autonomous Networks Project, “Intent common model,” Technical Report (TR) 290, TM Forum, Jul. 2024. Version 3.6.0. [Online] Avail- able on: https://www.tmforum.org/resources/introductory-guide/intent- common-model-v3-6-0-tr290/. [35] O. Asif, S. A. Haider, S. R. Naqvi, J. F. Zaki, K.-S. Kwak, and S. R. Islam, “A deep learning model for remaining useful life prediction of aircraft turbofan engine on c-mapss dataset,” Ieee Access, vol. 10, pp. 95425–95440, 2022.","type":"sentence","text_location":{"location":[[47,583,292,70]],"location_raw":[[47,258,292,771]]},"info":{}}]
"""

    json_response = json.loads(json_text)

    figure_dict: Dict[str, Tuple[str, str]] = {}
    figure_count = 1
    print(json_response)
    
    image_url_ids = []
    image_urls = []
    captions = []
    keys = []

    for i, item in enumerate(json_response):
        if item['type'] == 'image':
            image_url_ids.append(i)
            image_urls.append(item['image_detail'][0]['path'])

    for i in image_url_ids:
        sentence = json_response[i+1]['sentence']
        # 截取从 'Fig. or Figure' 开始到句子结束的字符串
        caption = re.search(r'(Fig\.|Figure).*', sentence).group()
        # 提取 caption 中的图编号数字
        figure_number = re.search(r'\d+', caption).group()
        keys.append(f"figure_{figure_number}")
        captions.append(caption)

    figure_dict = dict(zip(keys, zip(image_urls, captions)))

    print(figure_dict)
